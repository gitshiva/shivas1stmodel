{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e4ea0fb-fa23-4dd8-a25b-bcaf5fcf0615",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-27 23:45:23.175823: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-27 23:45:23.219523: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-27 23:45:23.219555: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-27 23:45:23.219579: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-27 23:45:23.227849: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-27 23:45:24.649513: I itex/core/wrapper/itex_cpu_wrapper.cc:60] Intel Extension for Tensorflow* AVX512 CPU backend is loaded.\n",
      "2024-02-27 23:45:24.846796: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-27 23:45:24.855863: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-27 23:45:24.859405: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "# adapted based on https://www.tensorflow.org/tutorials/keras/regression\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fab5f74c-3b9c-4fed-b857-0f9fd26ba7e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "raw_dataset = pd.read_csv('linear-relationship.csv')\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "615ea1c2-91c1-4a7f-8dec-a740071fb235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9995</td>\n",
       "      <td>19995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9996</td>\n",
       "      <td>19997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9997</td>\n",
       "      <td>19999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9998</td>\n",
       "      <td>20001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>9999</td>\n",
       "      <td>20003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x      y\n",
       "9995  9995  19995\n",
       "9996  9996  19997\n",
       "9997  9997  19999\n",
       "9998  9998  20001\n",
       "9999  9999  20003"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = raw_dataset.copy()\n",
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e707f69-43be-42a2-965c-d33dfece9fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         x      y\n",
      "8673  8673  17351\n",
      "8175  8175  16355\n",
      "4933  4933   9871\n",
      "504    504   1013\n",
      "107    107    219\n",
      "--\n",
      "         x      y\n",
      "9963  9963  19931\n",
      "9969  9969  19943\n",
      "9972  9972  19949\n",
      "9982  9982  19969\n",
      "9995  9995  19995\n"
     ]
    }
   ],
   "source": [
    "train_ds = dataset.sample(frac=0.8, random_state=0)\n",
    "test_ds = dataset.drop(train_ds.index)\n",
    "print(train_ds.tail())\n",
    "print('--')\n",
    "print(test_ds.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0f322dd-e193-4124-b57b-222ee68c6bfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>x</th>\n",
       "      <td>8000.0</td>\n",
       "      <td>5003.4595</td>\n",
       "      <td>2887.354272</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2493.75</td>\n",
       "      <td>5006.5</td>\n",
       "      <td>7517.25</td>\n",
       "      <td>9999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>8000.0</td>\n",
       "      <td>10011.9190</td>\n",
       "      <td>5774.708543</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4992.50</td>\n",
       "      <td>10018.0</td>\n",
       "      <td>15039.50</td>\n",
       "      <td>20003.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    count        mean          std  min      25%      50%       75%      max\n",
       "x  8000.0   5003.4595  2887.354272  1.0  2493.75   5006.5   7517.25   9999.0\n",
       "y  8000.0  10011.9190  5774.708543  7.0  4992.50  10018.0  15039.50  20003.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11f92ef2-6f09-48a7-bc85-a16c30b59812",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = train_ds.copy()\n",
    "test_features = test_ds.copy()\n",
    "\n",
    "train_labels = train_features.pop('y')\n",
    "test_labels = test_features.pop('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afc34765-5df3-4347-a59e-4657778fd78f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-27 23:45:25.173671: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-27 23:45:25.177288: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-27 23:45:25.180221: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-27 23:45:25.362936: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-27 23:45:25.364750: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-27 23:45:25.366476: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-27 23:45:25.368159: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6653 MB memory:  -> device: 0, name: Quadro RTX 4000, pci bus id: 0000:13:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "tsr_train_features = tf.convert_to_tensor(train_features)\n",
    "tsr_train_labels = tf.convert_to_tensor(train_labels)\n",
    "\n",
    "tsr_test_features = tf.convert_to_tensor(test_features)\n",
    "tsr_test_labels = tf.convert_to_tensor(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b0095a5-c080-4207-8609-89647f2d8503",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "#normalizer.adapt(np.array(tsr_train_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d38e89c8-ea97-4dfc-b25f-92625b0b242e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-27 23:45:25.562299: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type CPU is enabled.\n",
      "2024-02-27 23:45:26.037592: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "a = np.array(train_features)\n",
    "\n",
    "a_normalizer = layers.Normalization(input_shape=[1,], axis=None)\n",
    "a_normalizer.adapt(a)\n",
    "print ('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd19f9d8-64eb-4399-95cf-5f07a5efd2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dnn_model(norm):\n",
    "    model = keras.Sequential([\n",
    "        norm,\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    model.compile(loss='mean_absolute_error',\n",
    "        optimizer=tf.keras.optimizers.Adam(0.001))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18585199-d908-4631-b83f-8a232cd17ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizer\n",
    "\n",
    "a_dnn_model = build_dnn_model(a_normalizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "346a6b96-bd2d-491c-88d3-21cdb81e19ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization (Normalizati  (None, 1)                 3         \n",
      " on)                                                             \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                128       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4356 (17.02 KB)\n",
      "Trainable params: 4353 (17.00 KB)\n",
      "Non-trainable params: 3 (16.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "a_dnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c583803c-dc04-431d-9e97-2bac2d9ba378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-27 23:45:28.154723: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f1531cef9a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-02-27 23:45:28.154755: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 4000, Compute Capability 7.5\n",
      "2024-02-27 23:45:28.159893: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-02-27 23:45:28.178417: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8700\n",
      "2024-02-27 23:45:28.278229: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 2s 4ms/step - loss: 10031.7939 - val_loss: 9715.6396\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 9648.9648 - val_loss: 8964.2314\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 8436.2119 - val_loss: 7289.3950\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 5927.7568 - val_loss: 3936.8840\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 1736.5490 - val_loss: 492.5401\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 394.7886 - val_loss: 373.4446\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 300.8323 - val_loss: 290.0189\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 232.8318 - val_loss: 226.9003\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 180.1142 - val_loss: 177.5081\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 140.7601 - val_loss: 136.1967\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 110.2152 - val_loss: 106.0259\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 85.9668 - val_loss: 81.6932\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 67.0049 - val_loss: 66.1456\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 51.6758 - val_loss: 47.9022\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 40.8618 - val_loss: 36.7985\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 31.8943 - val_loss: 28.3552\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 25.1211 - val_loss: 22.6379\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 20.2216 - val_loss: 17.3559\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 15.0589 - val_loss: 15.3233\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 12.1735 - val_loss: 14.5886\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 9.6619 - val_loss: 8.5668\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 8.3189 - val_loss: 7.0008\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 6.9361 - val_loss: 7.3836\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 5.8217 - val_loss: 5.3241\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 5.0296 - val_loss: 4.4544\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 4.7756 - val_loss: 3.9480\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 4.2536 - val_loss: 4.1281\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 3.8755 - val_loss: 4.3132\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 3.8842 - val_loss: 4.2024\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 3.1245 - val_loss: 2.3979\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 2.8464 - val_loss: 3.5148\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 2.8502 - val_loss: 1.9094\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 2.7692 - val_loss: 4.7570\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 2.6042 - val_loss: 2.1524\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 2.9961 - val_loss: 1.9880\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 2.4955 - val_loss: 1.8919\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 2.8056 - val_loss: 1.6100\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 2.5370 - val_loss: 2.5980\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 2.2420 - val_loss: 4.0189\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 2.6139 - val_loss: 3.8495\n",
      "Epoch 41/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 2.3275 - val_loss: 1.6966\n",
      "Epoch 42/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 2.1529 - val_loss: 4.1341\n",
      "Epoch 43/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 2.5776 - val_loss: 3.2342\n",
      "Epoch 44/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 2.3274 - val_loss: 3.5309\n",
      "Epoch 45/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 2.1854 - val_loss: 2.3702\n",
      "Epoch 46/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 2.2747 - val_loss: 1.5621\n",
      "Epoch 47/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 1.8284 - val_loss: 1.2971\n",
      "Epoch 48/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 2.2372 - val_loss: 1.3241\n",
      "Epoch 49/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 2.0247 - val_loss: 1.5181\n",
      "Epoch 50/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 2.3298 - val_loss: 1.4555\n",
      "Epoch 51/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 2.4218 - val_loss: 2.1601\n",
      "Epoch 52/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 2.6859 - val_loss: 2.0775\n",
      "Epoch 53/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 2.2777 - val_loss: 2.2204\n",
      "Epoch 54/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 2.3969 - val_loss: 3.4033\n",
      "Epoch 55/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 2.0955 - val_loss: 1.8463\n",
      "Epoch 56/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 1.8909 - val_loss: 2.9449\n",
      "Epoch 57/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 2.3391 - val_loss: 0.9209\n",
      "Epoch 58/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 2.0194 - val_loss: 2.3304\n",
      "Epoch 59/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 1.7449 - val_loss: 2.3283\n",
      "Epoch 60/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 2.0155 - val_loss: 1.4331\n",
      "Epoch 61/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 1.8940 - val_loss: 1.1090\n",
      "Epoch 62/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 1.7843 - val_loss: 0.6027\n",
      "Epoch 63/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 1.9129 - val_loss: 2.2536\n",
      "Epoch 64/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 1.6272 - val_loss: 2.5388\n",
      "Epoch 65/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 1.9126 - val_loss: 2.0970\n",
      "Epoch 66/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 1.8175 - val_loss: 1.5789\n",
      "Epoch 67/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 2.2157 - val_loss: 3.1901\n",
      "Epoch 68/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 1.9600 - val_loss: 2.0307\n",
      "Epoch 69/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 1.8776 - val_loss: 1.1057\n",
      "Epoch 70/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 1.7837 - val_loss: 1.7654\n",
      "Epoch 71/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 1.9210 - val_loss: 0.8162\n",
      "Epoch 72/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 1.6818 - val_loss: 2.0485\n",
      "Epoch 73/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 2.0896 - val_loss: 1.8650\n",
      "Epoch 74/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 2.0766 - val_loss: 1.8972\n",
      "Epoch 75/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 1.5187 - val_loss: 1.4552\n",
      "Epoch 76/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 2.1750 - val_loss: 1.4321\n",
      "Epoch 77/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 1.8444 - val_loss: 3.3931\n",
      "Epoch 78/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 2.1487 - val_loss: 6.2089\n",
      "Epoch 79/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 2.6879 - val_loss: 3.1559\n",
      "Epoch 80/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 1.5853 - val_loss: 0.9843\n",
      "Epoch 81/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 1.6190 - val_loss: 0.6975\n",
      "Epoch 82/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 1.5485 - val_loss: 1.2252\n",
      "Epoch 83/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 1.6806 - val_loss: 1.3354\n",
      "Epoch 84/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 1.7091 - val_loss: 3.0389\n",
      "Epoch 85/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 1.4984 - val_loss: 0.6888\n",
      "Epoch 86/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 2.3472 - val_loss: 1.1116\n",
      "Epoch 87/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 1.5793 - val_loss: 2.4823\n",
      "Epoch 88/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 1.6626 - val_loss: 1.0263\n",
      "Epoch 89/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 2.0177 - val_loss: 1.2931\n",
      "Epoch 90/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 2.2483 - val_loss: 3.1947\n",
      "Epoch 91/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 1.4367 - val_loss: 1.9049\n",
      "Epoch 92/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 1.4947 - val_loss: 2.3500\n",
      "Epoch 93/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 1.7047 - val_loss: 1.8037\n",
      "Epoch 94/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 1.6364 - val_loss: 1.8311\n",
      "Epoch 95/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 1.8204 - val_loss: 3.6658\n",
      "Epoch 96/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 1.7290 - val_loss: 3.4564\n",
      "Epoch 97/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 1.8820 - val_loss: 0.8552\n",
      "Epoch 98/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 1.6439 - val_loss: 1.5913\n",
      "Epoch 99/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 2.1623 - val_loss: 4.8032\n",
      "Epoch 100/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 2.0916 - val_loss: 1.5872\n",
      "CPU times: user 51.7 s, sys: 3.25 s, total: 55 s\n",
      "Wall time: 47.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f15b07d0a30>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "a_dnn_model.fit(\n",
    "    train_features['x'],\n",
    "    train_labels,\n",
    "    validation_split=0.2,\n",
    "    epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a41739d3-0f87-4f9e-bc56-418e57263cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 108ms/step\n"
     ]
    }
   ],
   "source": [
    "a1 = [[11000]]\n",
    "b1 = a_dnn_model.predict(a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34b60fd8-9b0f-4b57-901e-386605293e3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[22008.01]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fabaa27-8a82-4225-bd5d-770810780389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred is pretty close to 22005, the actual value of the function."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
